This is my logbook.


1. SETUP
- logical file structure
- decided to split into
- DATA - ARCHITECTURE - TRAINING - EVALUATION - MAIN


2. DATA
- create splits for training and testing
- preprocessing is basically given by dataset.py and performed when loading data from the loader
- set up dataloaders
- potentially add further preprocessing or augmentation steps in refinement


3. ARCHITECTURE
    - I started with the PyTorch recommendation
    Conv2d
    MaxPool2d
    Conv2d
    Linear
    Linear
    Linear

    - Then did some research and chose the following approach
    Conv2d
    MaxPool2d
    Conv2d
    MaxPool2d
    Conv2d
    MaxPool2d
    Linear
    Linear

    - Adapted my model to get higher Accuracy


4. TRAINING
- all parameters are inputted into the function incl. loss and optimizer
- the overall flow will be similar to the assignement
-> epochs -> minibatches -> test evaluation


5. EVALUATION
- calculating the accuracy on my test split after training
- if i have time i would like to introduce a confusion matrix to analyse the different labels

6. MAIN
- bring it all together
-> load -> train -> save -> test -> adjust
- print statements for progress overview


RESULTS
1. Model: 41.73% Accuracy
    -> add dropout
    -> go deeper
    -> batch norm
2. Model: % Accuracy

